{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "807dd209-7326-4f56-b095-9fd79bf6f103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5af6d9c-a873-4e5e-b314-52cbc2f8f890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_ablation(results_dict, dataset_list, methods, metrics):\n",
    "    summary = dict()\n",
    "    for metric in metrics:\n",
    "        summary[metric] = []\n",
    "        \n",
    "        metric_arr = []\n",
    "        for dataset_name in dataset_list:\n",
    "            methods_perms = dict()\n",
    "            for method in methods:\n",
    "                methods_perms[method] = []\n",
    "            \n",
    "            outcomes = results_dict[model]['results_dic']\n",
    "            outcomes = outcomes[list(outcomes.keys())[0]]\n",
    "            \n",
    "            for seed in outcomes:\n",
    "                outcome = outcomes[seed][list(outcomes[seed].keys())[0]]\n",
    "                for m in outcome:\n",
    "                    if m in methods:\n",
    "                        methods_perms[m].append(outcome[m])\n",
    "            \n",
    "            values_to_plot = []\n",
    "            for method in methods:\n",
    "                acc_mean = np.mean(np.array([d[metric] for d in methods_perms[method]]))\n",
    "                acc_var = np.std(np.array([d[metric] for d in methods_perms[method]]))\n",
    "                values_to_plot.append((acc_mean, acc_var))\n",
    "            metric_arr.append(values_to_plot)\n",
    "        \n",
    "        summary[metric].append(methods)\n",
    "        # average accuracy over all datasets\n",
    "        summary[metric].append(np.mean(np.array([[v[0] for v in vs] for vs in metric_arr]),axis=0))\n",
    "        # average variance over all datasets \n",
    "        summary[metric].append(np.mean(np.array([[v[1] for v in vs] for vs in metric_arr]),axis=0)) \n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43d6fae9-5d77-46b0-bc20-8bcecc348b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_to_compare = ['LR-average_voting']\n",
    "metrics_to_compare = ['accuracy','macro_F1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "190fc38c-454c-47fa-b8f4-ef9650d9576e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': [['LR-6-average_voting'], array([0.65234375]), array([0.04934879])], 'macro_F1': [['LR-6-average_voting'], array([0.63602752]), array([0.06791602])]}\n"
     ]
    }
   ],
   "source": [
    "results_dir = '../results'\n",
    "\n",
    "model='Llama'\n",
    "dataset_name = 'subjective'\n",
    "\n",
    "file_path = os.path.join(results_dir, \"/hpc/home/jd420/Projects/ICL/results/results_k_[8]_seeds_5_datasets_['subjective']_models_['Llama']_.pkl\")\n",
    "with open(file_path,'rb') as f:\n",
    "    baseline_results = pickle.load(f)\n",
    "\n",
    "print(compute_metrics_ablation(baseline_results, ['subjective'], ['LR-6-average_voting'], metrics_to_compare))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc886538-b133-481c-90d2-a0dd31784e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': [['LR-average_voting'], array([0.43515625]), array([0.04276229])], 'macro_F1': [['LR-average_voting'], array([0.41064634]), array([0.02801832])]}\n"
     ]
    }
   ],
   "source": [
    "results_dir = '../results'\n",
    "\n",
    "model='Qwen'\n",
    "dataset_name = 'sst5'\n",
    "\n",
    "file_path = os.path.join(results_dir, \"/hpc/home/jd420/Projects/ICL/results/results_k_[8]_seeds_5_datasets_['sst5']_models_['Qwen']_.pkl\")\n",
    "with open(file_path,'rb') as f:\n",
    "    baseline_results = pickle.load(f)\n",
    "\n",
    "print(compute_metrics_ablation(baseline_results, ['sst5'], methods_to_compare, metrics_to_compare))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd19135a-98a3-414c-a724-6ea3366d462a",
   "metadata": {},
   "source": [
    "## Ablation on Fix Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7360a1a3-bf67-4f40-83f5-de95cdc2126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = '../results/Ablation'\n",
    "\n",
    "model='Llama'\n",
    "dataset_name = 'subjective'\n",
    "\n",
    "file_path = os.path.join(results_dir, f\"results_k_[8]_seeds_5_datasets_['{dataset_name}']_models_['{model}']_ablation_fix_weights.pkl\")\n",
    "with open(file_path,'rb') as f:\n",
    "    results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f728bca2-b9fb-4e42-9565-33920cd404b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': [['LR-average_voting'], array([0.615625]), array([0.03988203])], 'macro_F1': [['LR-average_voting'], array([0.59646778]), array([0.06592935])]}\n"
     ]
    }
   ],
   "source": [
    "print(compute_metrics_ablation(results, ['subjective'], methods_to_compare, metrics_to_compare))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae2bd3ed-8329-42a7-bf41-d0cf9c959978",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = '../results/Ablation'\n",
    "\n",
    "model='Qwen'\n",
    "dataset_name = 'sst5'\n",
    "\n",
    "file_path = os.path.join(results_dir, f\"results_k_[8]_seeds_5_datasets_['{dataset_name}']_models_['{model}']_ablation_fix_weights.pkl\")\n",
    "with open(file_path,'rb') as f:\n",
    "    results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14f1ee34-a247-4040-8ba4-b6f6abbc0af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': [['LR-average_voting'], array([0.4]), array([0.06218671])], 'macro_F1': [['LR-average_voting'], array([0.29417353]), array([0.04281093])]}\n"
     ]
    }
   ],
   "source": [
    "print(compute_metrics_ablation(results, ['subjective'], methods_to_compare, metrics_to_compare))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef18504-5100-4189-9a49-3abffb03e3d8",
   "metadata": {},
   "source": [
    "## Ablation on Invariance Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f4d3059-7147-4c1b-a2c3-7ad3d0dae041",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = '../results/Ablation'\n",
    "\n",
    "model='Llama'\n",
    "dataset_name = 'subjective'\n",
    "\n",
    "results_dicts = dict()\n",
    "for level in ['no', 'small', 'large']:\n",
    "    file_path = os.path.join(results_dir, f\"results_k_[8]_seeds_5_datasets_['{dataset_name}']_models_['{model}']_ablation_{level}_invar.pkl\")\n",
    "    with open(file_path,'rb') as f:\n",
    "        results_dicts[level] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c973810-5cee-4e64-9b82-1f59ce6574b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n",
      "{'accuracy': [['LR-average_voting'], array([0.61875]), array([0.04153136])], 'macro_F1': [['LR-average_voting'], array([0.60367096]), array([0.06001094])]}\n",
      "small\n",
      "{'accuracy': [['LR-average_voting'], array([0.5390625]), array([0.])], 'macro_F1': [['LR-average_voting'], array([0.35025381]), array([0.])]}\n",
      "large\n",
      "{'accuracy': [['LR-average_voting'], array([0.5390625]), array([0.])], 'macro_F1': [['LR-average_voting'], array([0.35025381]), array([0.])]}\n"
     ]
    }
   ],
   "source": [
    "for sample, results in results_dicts.items():\n",
    "    print(sample)\n",
    "    print(compute_metrics_ablation(results, ['subjective'], methods_to_compare, metrics_to_compare))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d327077c-df29-45c1-b593-229e540a02f1",
   "metadata": {},
   "source": [
    "## Ablation on the Number of K-learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71b75c58-2ced-47dc-8521-29a3d7ab1db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/hpc/home/jd420/Projects/ICL/results/results_k_[16]_seeds_5_datasets_['subjective']_models_['Llama']_ablation.pkl\",'rb') as f:\n",
    "    results_dicts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d77c5b76-d6e6-4fdd-9268-766699292a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [['LR-average_voting-first-2',\n",
       "   'LR-average_voting-first-3',\n",
       "   'LR-average_voting-first-4',\n",
       "   'LR-average_voting-first-5',\n",
       "   'LR-average_voting-first-6',\n",
       "   'LR-average_voting-first-7',\n",
       "   'LR-average_voting-first-8',\n",
       "   'LR-average_voting-first-9',\n",
       "   'LR-average_voting-first-10',\n",
       "   'LR-average_voting-first-11'],\n",
       "  array([0.52109375, 0.49140625, 0.49765625, 0.52265625, 0.5765625 ,\n",
       "         0.62890625, 0.63828125, 0.64453125, 0.6703125 , 0.68515625]),\n",
       "  array([0.04619295, 0.05586893, 0.06631888, 0.08169201, 0.07536532,\n",
       "         0.06743233, 0.06937746, 0.06652104, 0.0391873 , 0.03957477])],\n",
       " 'macro_F1': [['LR-average_voting-first-2',\n",
       "   'LR-average_voting-first-3',\n",
       "   'LR-average_voting-first-4',\n",
       "   'LR-average_voting-first-5',\n",
       "   'LR-average_voting-first-6',\n",
       "   'LR-average_voting-first-7',\n",
       "   'LR-average_voting-first-8',\n",
       "   'LR-average_voting-first-9',\n",
       "   'LR-average_voting-first-10',\n",
       "   'LR-average_voting-first-11'],\n",
       "  array([0.49323093, 0.40202427, 0.39615483, 0.41834487, 0.51956513,\n",
       "         0.60901878, 0.61396411, 0.62239991, 0.65414602, 0.67257517]),\n",
       "  array([0.06382357, 0.0934878 , 0.10944263, 0.13782915, 0.11654797,\n",
       "         0.08746256, 0.09822713, 0.08687776, 0.05330058, 0.0579302 ])]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods_k_learners = ['LR-average_voting-first-2', 'LR-average_voting-first-3', 'LR-average_voting-first-4', 'LR-average_voting-first-5', 'LR-average_voting-first-6', 'LR-average_voting-first-7', 'LR-average_voting-first-8', 'LR-average_voting-first-9', 'LR-average_voting-first-10', 'LR-average_voting-first-11']\n",
    "model = 'Llama'\n",
    "compute_metrics_ablation(results_dicts, ['subjective'], methods_k_learners, metrics_to_compare)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7d4230-9bbd-4c9f-af19-7f8aa791aa55",
   "metadata": {},
   "source": [
    "## Ablation on the Number of ICL Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06b74a27-e8c9-4c00-b327-49fab3c025e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = '../results/Ablation'\n",
    "\n",
    "model='Llama'\n",
    "dataset_name = 'subjective'\n",
    "\n",
    "results_dicts = dict()\n",
    "for sample in [4,12,24,48]:\n",
    "    file_path = os.path.join(results_dir, f\"results_k_[8]_seeds_5_datasets_['{dataset_name}']_models_['{model}']_ablation_samples_{sample}.pkl\")\n",
    "    with open(file_path,'rb') as f:\n",
    "        results_dicts[sample] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33feaa39-583b-4931-b9b7-c0714c803c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(results_dir, f\"results_k_[8]_seeds_5_datasets_['{dataset_name}']_models_['{model}']_ablation_samples_4.pkl\")\n",
    "with open(file_path,'rb') as f:\n",
    "    results_4 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d20b7152-f763-40a7-8af5-d10a1227d2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(results_dir, f\"results_k_[8]_seeds_5_datasets_['{dataset_name}']_models_['{model}']_ablation_samples_12.pkl\")\n",
    "with open(file_path,'rb') as f:\n",
    "    results_12 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e40f06c6-a903-4640-ad16-5fb01fb8f09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "{'accuracy': [['LR-average_voting'], array([0.5390625]), array([0.])], 'macro_F1': [['LR-average_voting'], array([0.35025381]), array([0.])]}\n",
      "12\n",
      "{'accuracy': [['LR-average_voting'], array([0.5390625]), array([0.])], 'macro_F1': [['LR-average_voting'], array([0.35025381]), array([0.])]}\n",
      "24\n",
      "{'accuracy': [['LR-average_voting'], array([0.5390625]), array([0.])], 'macro_F1': [['LR-average_voting'], array([0.35025381]), array([0.])]}\n",
      "48\n",
      "{'accuracy': [['LR-average_voting'], array([0.5390625]), array([0.])], 'macro_F1': [['LR-average_voting'], array([0.35025381]), array([0.])]}\n"
     ]
    }
   ],
   "source": [
    "for sample, results in results_dicts.items():\n",
    "    print(sample)\n",
    "    print(compute_metrics_ablation(results, ['subjective'], methods_to_compare, metrics_to_compare))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78d6197-9242-4dda-aa36-788f733f576c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CARE",
   "language": "python",
   "name": "care"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
